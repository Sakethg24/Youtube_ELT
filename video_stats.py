import requests
import json
import os 
from dotenv import load_dotenv
from datetime import date 

load_dotenv()

API_KEY = os.getenv("API_KEY")
handle = "casey"

max_results = 50

def get_playlist_id():
    try:
        url = f"https://youtube.googleapis.com/youtube/v3/channels?part=contentDetails&forHandle={handle}&key={API_KEY}"

        response = requests.get(url)
        response.raise_for_status()

        data = response.json()


        channel_items = data["items"][0]
        channel_playlistID = channel_items["contentDetails"]["relatedPlaylists"]

        return channel_playlistID
    
    except requests.exceptions.RequestException as e:
        raise e 
    




def get_video_ids(playlistID):
    video_ids =[]

    pageToken = None 
    base_url = f"https://youtube.googleapis.com/youtube/v3/playlistItems?part=contentDetails&maxResults={max_results}&playlistId={playlistID}&key={API_KEY}"

    try:
        while True:
            url = base_url
            if pageToken:
                url += f"&pageToken={pageToken}"
            
            response = requests.get(url)
            response.raise_for_status()

            data = response.json()
            
            for item in data.get('items',[]):
                video_id =item['contentDetails']['videoId']
                video_ids.append(video_id)

            pageToken = data.get('nextPageToken')

            if not pageToken:
                break
        return video_ids
    except requests.exceptions.RequestException as e:
        raise e 
    




def extract_video_data(video_ids):
    extracted_data = []
    def batch_list(video_id_list, batch_size):
        for video_id in range(0,len(video_id_list),batch_size):
            yield video_id_list[video_id:video_id+batch_size]

    try:
        for batch in batch_list(video_ids,max_results):
            video_ids_str = ",".join(batch)

            url = f'https://youtube.googleapis.com/youtube/v3/videos?part=contentDetails&part=snippet&part=statistics&id={video_ids_str}&key={API_KEY}'
            
            response = requests.get(url)
            response.raise_for_status()

            data = response.json()


            for item in data.get("items",[]):
                video_id = item['id']
                snippet = item['snippet']
                contentDetails = item['contentDetails']
                statistics = item['statistics']

                video_data = {
                    "video_id":video_id,
                    "title":snippet['title'],
                    "publishedAt":snippet['publishedAt'],
                    "duration":contentDetails['duration'],
                    "likeCount":statistics.get('likeCount'),
                    "viewCount":statistics.get('viewCount'),
                    "commentCount":statistics.get('commentCount')
                }

                extracted_data.append(video_data)
            return extracted_data
    except requests.exceptions.RequestException as e:
        raise e

def save_to_json(extracted_data):
    file_path = f"/Users/sakethgurram/Youtube_ELT/data_{date.today()}.json"
    with open(file_path,"w",encoding="utf-8") as json_outfile:
        json.dump(extracted_data, json_outfile, indent=4, ensure_ascii=False)

if __name__ == "__main__":
    playlistID = get_playlist_id()["uploads"]
    video_ids = get_video_ids(playlistID)
    print(extract_video_data(video_ids))